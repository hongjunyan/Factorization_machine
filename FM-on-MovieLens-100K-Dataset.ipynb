{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "在設計一個推薦系統模型時，最常用的作法之一就是透過使用者(user)和物品(item)的關聯性來建立模型，模型的輸入是user和item，輸出是模型預測user喜歡item的分數。具體來說，模型是一個函式f(user, item)= rate, user,item和rate是在database的一筆資料，rate則是這位user喜歡這個item的分數。在這篇文章中，我們訓練資料選用MovieLens資料集，模型使用[Factorization Machine](https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf)的方法，建立函式如下:$$rate = {w_0} + \\sum_{i=1}^{n} {w_i}{x_i} + \\sum_{i=1}^{n}\\sum_{j=i+1}^{n} <{v_i},{v_j}>{x_i}{x_j}$$，${x}$是欄位的向量表示法（以MovieLens資料集為例，$x_0$是user_id, $x_1$是movie_id），${w_i}$是一階交互關係，就是自己跟自己的關係， $<{v_i},{v_j}>$的運算是${v_i}$,${v_j}$兩個vector做dot product, 代表$x_i$和$x_j$的關係，又稱二階交互關係。而計算${v}$和${x}$的作法是這樣的，我們舉MovieLens欄位0為例, 也就是user id，一開始先初始化兩張table，第一個是用來查user id對應到的embedding,也就是${x_0}$, 另一個是查${v_0}$，也就是說一個user id對應到兩個embedding，其中${x}$包含了自己欄位的特徵，並透過${w}$和別的欄位做weighted sum，${v}$則是透過$<{v_i},{v_j}>$來計算和其他欄位的關聯性。最後我們只要給一個user，例如：Jun，和一部電影《鬼影特攻：以暴制暴》，模型就可以預測Jun對於《鬼影特攻：以暴制暴》的喜愛程度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MovieLens Data \n",
    "#### dataset download: http://files.grouplens.org/datasets/movielens/ml-100k.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rate</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>874965758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90565</th>\n",
       "      <td>943</td>\n",
       "      <td>1047</td>\n",
       "      <td>2</td>\n",
       "      <td>875502146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90566</th>\n",
       "      <td>943</td>\n",
       "      <td>1074</td>\n",
       "      <td>4</td>\n",
       "      <td>888640250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90567</th>\n",
       "      <td>943</td>\n",
       "      <td>1188</td>\n",
       "      <td>3</td>\n",
       "      <td>888640250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90568</th>\n",
       "      <td>943</td>\n",
       "      <td>1228</td>\n",
       "      <td>3</td>\n",
       "      <td>888640275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90569</th>\n",
       "      <td>943</td>\n",
       "      <td>1330</td>\n",
       "      <td>3</td>\n",
       "      <td>888692465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90570 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id  rate  timestamp\n",
       "0            1         1     5  874965758\n",
       "1            1         2     3  876893171\n",
       "2            1         3     4  878542960\n",
       "3            1         4     3  876893119\n",
       "4            1         5     3  889751712\n",
       "...        ...       ...   ...        ...\n",
       "90565      943      1047     2  875502146\n",
       "90566      943      1074     4  888640250\n",
       "90567      943      1188     3  888640250\n",
       "90568      943      1228     3  888640275\n",
       "90569      943      1330     3  888692465\n",
       "\n",
       "[90570 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./ml-100k/ua.base\", header=None, delimiter='\\t')\n",
    "df.columns = [\"user_id\", \"movie_id\", \"rate\", \"timestamp\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: You have a CUDA device\n"
     ]
    }
   ],
   "source": [
    "# import for Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# for time\n",
    "from time import time\n",
    "\n",
    "# load parameters\n",
    "from bunch import Bunch\n",
    "args = Bunch({\n",
    "    'epochs':20,\n",
    "    'lr':1e-3,\n",
    "    'batch_size':128,\n",
    "    'eval_step':500,\n",
    "    'load_dir':'./model_save',\n",
    "    'save_dir':'./model_save',\n",
    "    'seed':1,\n",
    "    'device': None\n",
    "})\n",
    "\n",
    "###############\n",
    "\"\"\"device\"\"\"\n",
    "use_gpu = args.device is not None\n",
    "if torch.cuda.is_available() and not use_gpu:\n",
    "    print(\"WARNING: You have a CUDA device\")\n",
    "# set cuda device and seed\n",
    "if use_gpu:\n",
    "    torch.cuda.set_device(args.device)\n",
    "    \n",
    "\"\"\"set seed\"\"\"\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import pandas as pd\n",
    "import json\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, csv_file, header=None, delimiter='\\t'):\n",
    "        \"\"\"\n",
    "        user_id: 1~943\n",
    "        movie_id: 1~1682（其實裡面只有1680個，代表有兩個movie id是沒有在裡面的）\n",
    "        \"\"\"\n",
    "        self.dataframe = pd.read_csv(csv_file, header=header, delimiter=delimiter)\n",
    "        self.column_num = len(self.dataframe.columns)\n",
    "        # rename column\n",
    "        self.rename_column(['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "\n",
    "        # however len(self.dataframe['movie_id'].value_counts()) == 1680\n",
    "        self.user_num = self.dataframe['user_id'].value_counts().keys().max()\n",
    "        self.movie_num = self.dataframe['movie_id'].value_counts().keys().max() # 1682\n",
    "        \n",
    "        # 分數是1~6分，我們將大於三分的label設成True, 小於的label設成False\n",
    "        # set labels = True if rating >3 else labels=False\n",
    "        self.dataframe['labels'] = self.dataframe['rating']>3\n",
    "    \n",
    "    def rename_column(self, name_list):\n",
    "        assert self.column_num == len(name_list)\n",
    "        self.dataframe.columns = name_list\n",
    "        \n",
    "    def show_labels_proportion(self):\n",
    "        #label_True_count/Total_num_of_dataframe\n",
    "        return self.dataframe['labels'].sum()/len(self.dataframe['labels'])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return json.loads(self.dataframe.iloc[idx].to_json(orient='columns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels proportion(True_count/Total_num) 0.5510213094843768\n",
      "Train labels proportion(True_count/Total_num) 0.5799575821845175\n"
     ]
    }
   ],
   "source": [
    "# load training dataset\n",
    "train_dataset = Dataset('./ml-100k/ua.base')\n",
    "\n",
    "# load testing dataset\n",
    "test_dataset = Dataset('./ml-100k/ua.test')\n",
    "\n",
    "print(\"Train labels proportion(True_count/Total_num)\", train_dataset.show_labels_proportion())\n",
    "print(\"Train labels proportion(True_count/Total_num)\", test_dataset.show_labels_proportion())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_num = train_dataset.user_num\n",
    "movie_num = train_dataset.movie_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size:81513, validation size:9057, test size:9430\n"
     ]
    }
   ],
   "source": [
    "# split train val dataset\n",
    "from torch.utils.data import random_split\n",
    "val_size = int(len(train_dataset)*0.1)\n",
    "train_size = len(train_dataset) - val_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "print(\"train size:{}, validation size:{}, test size:{}\".format(train_size, val_size, len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataLoader\n",
    "train_iter = DataLoader(dataset=train_dataset,\n",
    "                        batch_size=args.batch_size)\n",
    "\n",
    "val_iter = DataLoader(dataset=val_dataset,\n",
    "                        batch_size=args.batch_size)\n",
    "\n",
    "test_iter = DataLoader(dataset=test_dataset,\n",
    "                        batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baic module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "# ref: https://github.com/hpzhao/SummaRuNNer/tree/47de2c0cc81f0464490ec43a7504e6d3075a2742\n",
    "class BasicModule(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super(BasicModule,self).__init__()\n",
    "        self.args = args\n",
    "        self.model_name = str(type(self))\n",
    "    \n",
    "    def save(self):\n",
    "        checkpoint = {'model':self.state_dict(), 'args': self.args}\n",
    "        best_path = '%s_%s_seed_%d.pt' % (self.args.save_dir,self.model_name,self.args.seed)\n",
    "        torch.save(checkpoint,best_path)\n",
    "\n",
    "        return best_path\n",
    "\n",
    "    def load(self, best_path):\n",
    "        if best_path == \"\":\n",
    "            best_path = self.args.load_dir\n",
    "        if self.args.device is not None:\n",
    "            data = torch.load(best_path)['model']\n",
    "        else:\n",
    "            data = torch.load(best_path, map_location=lambda storage, loc: storage)['model']\n",
    "        self.load_state_dict(data)\n",
    "        if self.args.device is not None:\n",
    "            return self.cuda()\n",
    "        else:\n",
    "            return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf\n",
    "# https://www.kaggle.com/gennadylaptev/factorization-machine-implemented-in-pytorch/data\n",
    "class FM(BasicModule):\n",
    "    def __init__(self, args, n=None, k=None):\n",
    "        super(FM, self).__init__(args)\n",
    "        self.model_name = 'FM'\n",
    "        # Initially we fill V with random values sampled from Gaussian distribution\n",
    "        # use nn.Parameter to compute gradients\n",
    "        self.args = args\n",
    "        self.V = nn.Parameter(torch.FloatTensor(n, k).normal_(0,1))\n",
    "        self.linear = nn.Linear(n, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out_1 = torch.matmul(x, self.V).pow(2).sum(1, keepdim=True) #S_1^2\n",
    "        out_2 = torch.matmul(x.pow(2), self.V.pow(2)).sum(1, keepdim=True) # S_2\n",
    "        # out_1, out_2 shape are (B, k) \n",
    "        out_inter = 0.5*(out_1 - out_2)\n",
    "        out_lin = self.linear(x)\n",
    "        out = out_inter + out_lin\n",
    "        out = torch.sigmoid(out) # (B,1)\n",
    "        return out.squeeze() # (B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FM with embedding layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The same as FM, but using nn.Embedding can be more convient to extend the first and seconder order parameter, \n",
    "i.e., you can modify the dimension of nn.Embedding from nn.Embedding(feature_size,1) \n",
    "to nn.Embedding(feature_size, D_model), the value of D_model is up to you\n",
    "\"\"\"\n",
    "# ref: https://github.com/chenxijun1029/DeepFM_with_PyTorch\n",
    "class FM_emb(BasicModule):\n",
    "    def __init__(self, args, feature_sizes, k=None):\n",
    "        super(FM_emb, self).__init__(args)\n",
    "        self.model_name = 'FM_emb'\n",
    "        self.feature_sizes = feature_sizes # list [field1_categories_num, field2_categories_num, ...]\n",
    "        self.args = args\n",
    "        self.embedding_size = k\n",
    "        self.first_order_embeddings = nn.ModuleList([nn.Embedding(feature_size,1) for feature_size in self.feature_sizes])\n",
    "        self.second_order_embeddings = nn.ModuleList([nn.Embedding(feature_size, self.embedding_size) for feature_size in self.feature_sizes])\n",
    "        \n",
    "        \n",
    "    def forward(self, x, values, use_sigmoid=True):\n",
    "        fields_first_order = [torch.sum(emb(x[:,i]), dim=1, keepdim=True)*values[:,i].unsqueeze(1) for i, emb in enumerate(self.first_order_embeddings)] # [(B,1), (B,1)]\n",
    "        fm_first_order = sum(fields_first_order)# (B,2) sum-> (B,1)\n",
    "        \n",
    "        # a,b are vector\n",
    "        # use 2*a.dot(b)xy = (ax+by)^2 - a^2x^2 - b^2y^2 reduce calculation\n",
    "        fm_second_order_emb_arr = [torch.sum(emb(x[:,i]), dim=1, keepdim=True)*values[:,i].unsqueeze(1) for i, emb in enumerate(self.second_order_embeddings)] # [(B,1), (B,1)]\n",
    "        fm_sum_second_order_emb = sum(fm_second_order_emb_arr)\n",
    "        fm_sum_second_order_emb_square = fm_sum_second_order_emb*fm_sum_second_order_emb # (x+y)^2\n",
    "        fm_second_order_emb_square = [item*item for item in fm_second_order_emb_arr]\n",
    "        fm_second_order_emb_square_sum = sum(fm_second_order_emb_square) #x^2+y^2\n",
    "        fm_second_order = (fm_sum_second_order_emb_square - fm_second_order_emb_square_sum) * 0.5\n",
    "        \n",
    "        out = fm_first_order + fm_second_order\n",
    "        if use_sigmoid:\n",
    "            return torch.sigmoid(out).squeeze() # (B,1) squeeze-> (B)\n",
    "        else:\n",
    "            return out.squeeze() # (B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.csie.ntu.edu.tw/~cjlin/papers/ffm.pdf\n",
    "class FFM_emb(BasicModule):\n",
    "    def __init__(self, args, feature_sizes, k=None):\n",
    "        super(FFM_emb, self).__init__(args)\n",
    "        self.model_name = 'FFM_emb'\n",
    "        self.feature_sizes = feature_sizes # list [field1_categories_num, field2_categories_num, ...]\n",
    "        self.field_sizes = len(feature_sizes)\n",
    "        self.args = args\n",
    "        self.embedding_size = k\n",
    "        self.first_order_embeddings = nn.ModuleList([nn.Embedding(feature_size,1) for feature_size in self.feature_sizes])\n",
    "        self.second_order_embeddings = nn.ModuleList([nn.ModuleList([nn.Embedding(feature_size, self.embedding_size) for _ in range(self.field_sizes)]) for feature_size in self.feature_sizes])\n",
    "    \n",
    "    def forward(self, x, values, use_sigmoid=True):\n",
    "        # first order relation\n",
    "        \"\"\"\n",
    "        x shape: (B, Field_num)\n",
    "        value shape: (B, Field_num)\n",
    "        \"\"\"\n",
    "        # or (torch.sum(emb(x[:,i]), dim=1, keepdim=True).t()*values[:,i]).t()\n",
    "        fields_first_order = [torch.sum(emb(x[:,i]), dim=1, keepdim=True)*values[:,i].unsqueeze(1) for i, emb in enumerate(self.first_order_embeddings)] # [(B,1), (B,1)]\n",
    "        fm_first_order = sum(fields_first_order)# (B,1)+(B,1)+...-> (B,1)\n",
    "        \n",
    "        # second order relation\n",
    "        \"\"\"\n",
    "        fm_second_order_emb_arr (field_sizes, field_sizes)\n",
    "        |[(B,1), (B,1), (B,1) ...]\n",
    "        |[(B,1), (B,1), (B,1) ...]\n",
    "        |[(B,1), (B,1), (B,1) ...]\n",
    "                . \n",
    "                .\n",
    "                .\n",
    "        \"\"\"\n",
    "        ffm_second_order_emb_arr = [[torch.sum(emb(x[:,i]), dim=1, keepdim=True)*values[:,i].unsqueeze(1) for emb in field_embs] for i, field_embs in enumerate(self.second_order_embeddings)]\n",
    "        ffm_wij_arr = []\n",
    "        for i in range(self.field_sizes):\n",
    "            for j in range(i+1, self.field_sizes):\n",
    "                ffm_wij_arr.append(ffm_second_order_emb_arr[i][j]*ffm_second_order_emb_arr[j][i])\n",
    "        ffm_second_order = sum(ffm_wij_arr)\n",
    "        out = fm_first_order + ffm_second_order\n",
    "        if use_sigmoid:\n",
    "            return torch.sigmoid(out).squeeze() # (B,1) squeeze-> (B)\n",
    "        else:\n",
    "            return out.squeeze() # (B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build FM model\n",
    "criterion = nn.BCELoss()\n",
    "#model = FFM_emb(args, [user_num, movie_num], k=8)\n",
    "model = FM_emb(args, [user_num, movie_num], k=64)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "if use_gpu:\n",
    "    model.cuda()\n",
    "    criterion.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess in batch(convert id to one hot encoding)\n",
    "def one_hot_encoding(idx_tensor, dim=None):\n",
    "    # only FM need this, FM_emb, FFM_emb doesn't\n",
    "    if dim==None:\n",
    "        print('Please assign a dimension num, e.g. one_hot_encoding(...,dim=10)')\n",
    "        return\n",
    "    one_hot = torch.zeros(idx_tensor.size(0), dim)\n",
    "    one_hot[torch.arange(idx_tensor.size(0)), idx_tensor] = 1\n",
    "    return one_hot\n",
    "\n",
    "def convert_feature(batch, use_one_hot=True):\n",
    "    \"\"\"\n",
    "    'user_id': [user_id, ...]\n",
    "    'movie_id': [movie_id, ...]\n",
    "    'labels': [label, ...]\n",
    "    \"\"\"\n",
    "    # convert one hot encoding\n",
    "    # the index should be minus 1, due to the id is start from 1\n",
    "    if use_one_hot:\n",
    "        users_vec = one_hot_encoding(batch['user_id']-1, dim=user_num) # B x user_num\n",
    "        movies_vec = one_hot_encoding(batch['movie_id']-1, dim=movie_num) # B x movie_num\n",
    "    else:\n",
    "        users_vec = (batch['user_id']-1).unsqueeze(1).type(torch.LongTensor)\n",
    "        movies_vec = (batch['movie_id']-1).unsqueeze(1).type(torch.LongTensor)\n",
    "    labels = batch['labels'].float()\n",
    "    \n",
    "    # concat fields vector\n",
    "    features = torch.cat((users_vec, movies_vec), dim=-1) # B x (user_num+movie_num)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def validation(model, val_iter, criterion):\n",
    "    model.eval().cpu()\n",
    "    y_pred = []\n",
    "    y = []\n",
    "    total_loss = 0.0\n",
    "    for nbatch, batch in enumerate(val_iter):\n",
    "        features, labels = convert_feature(batch, use_one_hot=False)\n",
    "        values = torch.ones(features.shape)\n",
    "        probs = model(features, values)\n",
    "        loss = criterion(probs, labels)\n",
    "        total_loss += loss.item()\n",
    "        y.extend(labels.data.numpy())\n",
    "        y_pred.extend(probs.data.numpy())\n",
    "    total_loss = total_loss/(nbatch+1)\n",
    "    results = roc_auc_score(y, y_pred)\n",
    "    if use_gpu:\n",
    "        model.train().cuda()\n",
    "    else:\n",
    "        model.train()\n",
    "    return total_loss, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0] save model:./model_save_FM_emb_seed_1.pt\n",
      "[1, 0], cur_loss 11.345163056548213, roc_auc:0.5114522058932062, batch_loss 10.903482437133789\n",
      "[1, 500] save model:./model_save_FM_emb_seed_1.pt\n",
      "[1, 500], cur_loss 3.373172189148379, roc_auc:0.5141295337521764, batch_loss 3.0293455123901367\n",
      "Epoch 1, train loss:2.5038247130916482, roc_auc:0.5307565864419732\n",
      "[2, 0] save model:./model_save_FM_emb_seed_1.pt\n",
      "[2, 0], cur_loss 2.5234663335370344, roc_auc:0.5217247304196952, batch_loss 2.1613426208496094\n",
      "[2, 500] save model:./model_save_FM_emb_seed_1.pt\n",
      "[2, 500], cur_loss 1.209699400713746, roc_auc:0.5351489105100254, batch_loss 0.8595420122146606\n",
      "Epoch 2, train loss:1.0324237423377285, roc_auc:0.563045984870705\n",
      "[3, 0] save model:./model_save_FM_emb_seed_1.pt\n",
      "[3, 0], cur_loss 1.0336723671832555, roc_auc:0.5462986251704588, batch_loss 1.3454794883728027\n",
      "[3, 500] save model:./model_save_FM_emb_seed_1.pt\n",
      "[3, 500], cur_loss 0.8693184735069812, roc_auc:0.5626877654793541, batch_loss 0.8493895530700684\n",
      "Epoch 3, train loss:0.8004305412293977, roc_auc:0.5937492371875419\n",
      "[4, 0] save model:./model_save_FM_emb_seed_1.pt\n",
      "[4, 0], cur_loss 0.8407664408146496, roc_auc:0.5715973082019602, batch_loss 1.2367982864379883\n",
      "[4, 500] save model:./model_save_FM_emb_seed_1.pt\n",
      "[4, 500], cur_loss 0.7774345874786377, roc_auc:0.602058810042394, batch_loss 0.7605971693992615\n",
      "Epoch 4, train loss:0.7150463058585462, roc_auc:0.6423599268843936\n",
      "[5, 0] save model:./model_save_FM_emb_seed_1.pt\n",
      "[5, 0], cur_loss 0.7611625488375274, roc_auc:0.6151655170228565, batch_loss 0.8821994066238403\n",
      "[5, 500] save model:./model_save_FM_emb_seed_1.pt\n",
      "[5, 500], cur_loss 0.7131994047635039, roc_auc:0.6653961838083942, batch_loss 0.6770736575126648\n",
      "Epoch 5, train loss:0.644749441691433, roc_auc:0.7093733323959069\n",
      "[6, 0] save model:./model_save_FM_emb_seed_1.pt\n",
      "[6, 0], cur_loss 0.7025230191123317, roc_auc:0.6734329153365022, batch_loss 0.7020431756973267\n",
      "[6, 500] save model:./model_save_FM_emb_seed_1.pt\n",
      "[6, 500], cur_loss 0.6779541566338337, roc_auc:0.6956807568145646, batch_loss 0.645592987537384\n",
      "Epoch 6, train loss:0.6137656660712495, roc_auc:0.7339278196497934\n",
      "[7, 0] save model:./model_save_FM_emb_seed_1.pt\n",
      "[7, 0], cur_loss 0.6709705910212557, roc_auc:0.6974161206768797, batch_loss 0.6425397992134094\n",
      "[7, 500] save model:./model_save_FM_emb_seed_1.pt\n",
      "[7, 500], cur_loss 0.6605613378571792, roc_auc:0.7094099866191419, batch_loss 0.6258490681648254\n",
      "Epoch 7, train loss:0.5999017934222798, roc_auc:0.7447052739695\n",
      "[8, 0], cur_loss 0.6570077664415601, roc_auc:0.7088869001615583, batch_loss 0.6137437224388123\n",
      "[8, 500] save model:./model_save_FM_emb_seed_1.pt\n",
      "[8, 500], cur_loss 0.6510967964857397, roc_auc:0.7174911717628666, batch_loss 0.6216816902160645\n",
      "Epoch 8, train loss:0.5911696230878636, roc_auc:0.7513139750527963\n",
      "[9, 0], cur_loss 0.649786458888524, roc_auc:0.7155980676773457, batch_loss 0.5940260887145996\n",
      "[9, 500] save model:./model_save_FM_emb_seed_1.pt\n",
      "[9, 500], cur_loss 0.6447909121782007, roc_auc:0.7234389031671836, batch_loss 0.6179171204566956\n",
      "Epoch 9, train loss:0.5848210798795781, roc_auc:0.7564858978226954\n",
      "[10, 0], cur_loss 0.6455882502273774, roc_auc:0.7204456028461335, batch_loss 0.5808356404304504\n",
      "[10, 500] save model:./model_save_FM_emb_seed_1.pt\n",
      "[10, 500], cur_loss 0.6409449845972196, roc_auc:0.7284600706652584, batch_loss 0.616101861000061\n",
      "Epoch 10, train loss:0.5794824131616805, roc_auc:0.760963297171533\n",
      "[11, 0], cur_loss 0.64245747092744, roc_auc:0.7242989711558766, batch_loss 0.5771194696426392\n",
      "[11, 500] save model:./model_save_FM_emb_seed_1.pt\n",
      "[11, 500], cur_loss 0.6387548723690947, roc_auc:0.732403404039921, batch_loss 0.6123237013816833\n",
      "Epoch 11, train loss:0.5752150756504323, roc_auc:0.7646301623263694\n",
      "[12, 0], cur_loss 0.6411844475168578, roc_auc:0.7271569917689715, batch_loss 0.5669656991958618\n",
      "[12, 500] save model:./model_save_FM_emb_seed_1.pt\n",
      "[12, 500], cur_loss 0.636883943853244, roc_auc:0.7359008728161147, batch_loss 0.6098310947418213\n",
      "Epoch 12, train loss:0.5715258318457161, roc_auc:0.7678915646138013\n",
      "[13, 0], cur_loss 0.6401076560289087, roc_auc:0.7300111500590714, batch_loss 0.5633628964424133\n",
      "[13, 500] save model:./model_save_FM_emb_seed_1.pt\n",
      "[13, 500], cur_loss 0.6294634241453358, roc_auc:0.7388536556468934, batch_loss 0.6058911085128784\n",
      "Epoch 13, train loss:0.5685507057225873, roc_auc:0.770570239789387\n",
      "[14, 0], cur_loss 0.6325479191793523, roc_auc:0.7325038736393553, batch_loss 0.5577332973480225\n",
      "[14, 500] save model:./model_save_FM_emb_seed_1.pt\n",
      "[14, 500], cur_loss 0.635470941872664, roc_auc:0.7409937761986043, batch_loss 0.6030799746513367\n",
      "Epoch 14, train loss:0.5659063734476757, roc_auc:0.7729914633455893\n",
      "[15, 0], cur_loss 0.6323814937766169, roc_auc:0.7343215517229502, batch_loss 0.5547626614570618\n",
      "[15, 500] save model:./model_save_FM_emb_seed_1.pt\n",
      "[15, 500], cur_loss 0.627767779457737, roc_auc:0.74309320705456, batch_loss 0.60009765625\n",
      "Epoch 15, train loss:0.5636946584684321, roc_auc:0.7750808890756982\n",
      "[16, 0], cur_loss 0.6322931932731414, roc_auc:0.7363825807560076, batch_loss 0.5497063398361206\n",
      "[16, 500] save model:./model_save_FM_emb_seed_1.pt\n",
      "[16, 500], cur_loss 0.6274926234299029, roc_auc:0.7446908311305792, batch_loss 0.5988589525222778\n",
      "Epoch 16, train loss:0.561515026835482, roc_auc:0.7770962247586617\n",
      "[17, 0], cur_loss 0.6326942897178758, roc_auc:0.738017450418105, batch_loss 0.5511453151702881\n",
      "[17, 500] save model:./model_save_FM_emb_seed_1.pt\n",
      "[17, 500], cur_loss 0.6274564921016424, roc_auc:0.7465182757251868, batch_loss 0.5958200097084045\n",
      "Epoch 17, train loss:0.5595608846733297, roc_auc:0.7790296082428863\n",
      "[18, 0], cur_loss 0.6324922669101769, roc_auc:0.7398086088571874, batch_loss 0.5450202822685242\n",
      "[18, 500] save model:./model_save_FM_emb_seed_1.pt\n",
      "[18, 500], cur_loss 0.63564165755057, roc_auc:0.7473029669135208, batch_loss 0.5941804051399231\n",
      "Epoch 18, train loss:0.5580328173783361, roc_auc:0.7805796309884562\n",
      "[19, 0], cur_loss 0.6337569221644335, roc_auc:0.7406388852971745, batch_loss 0.5396468639373779\n",
      "[19, 500] save model:./model_save_FM_emb_seed_1.pt\n",
      "[19, 500], cur_loss 0.6306824314762169, roc_auc:0.7485079870871473, batch_loss 0.5926463007926941\n",
      "Epoch 19, train loss:0.5564578184433971, roc_auc:0.7821720956015487\n",
      "[20, 0], cur_loss 0.6336342579042408, roc_auc:0.7418051838377183, batch_loss 0.5385898947715759\n",
      "[20, 500] save model:./model_save_FM_emb_seed_1.pt\n",
      "[20, 500], cur_loss 0.6398543098442991, roc_auc:0.7489313911703656, batch_loss 0.5917053818702698\n",
      "Epoch 20, train loss:0.5547215746279975, roc_auc:0.7836626540376147\n"
     ]
    }
   ],
   "source": [
    "stime = time()\n",
    "model.train()\n",
    "total_loss = []\n",
    "best_roc = -float('inf')\n",
    "for epoch in range(1,args.epochs+1):\n",
    "    etime = time()\n",
    "    for nbatch, batch in enumerate(train_iter):\n",
    "        \"\"\"\n",
    "        feature shape: (B, Field_num)\n",
    "        values shape: (B, Field_num)\n",
    "        \"\"\"\n",
    "        # only FM requires ont_hot_encoding, FM_emb, FFM_emb do not need\n",
    "        # so use_one_hot=True for FM, otherwise use_one_hot=False\n",
    "        features, labels = convert_feature(batch, use_one_hot=False)\n",
    "        \n",
    "        # value in original category. However, in this datase all of values are 1\n",
    "        values = torch.ones(features.shape)\n",
    "        if use_gpu:\n",
    "            features, labels, values = features.cuda(), labels.cuda(), values.cuda()\n",
    "        probs = model(features, values)\n",
    "        loss = criterion(probs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if nbatch % args.eval_step==0:\n",
    "            cur_loss, roc_auc = validation(model, val_iter, criterion)\n",
    "            if best_roc < roc_auc:\n",
    "                best_roc = roc_auc\n",
    "                best_path = model.save()\n",
    "                print(f\"[{epoch}, {nbatch}] save model:{best_path}\")\n",
    "            print(f\"[{epoch}, {nbatch}], cur_loss {cur_loss}, roc_auc:{roc_auc}, batch_loss {loss.item()}\")\n",
    "    epoch_loss, roc_auc = validation(model, train_iter, criterion)\n",
    "    total_loss.append(epoch_loss)\n",
    "    print(f\"Epoch {epoch}, train loss:{epoch_loss}, roc_auc:{roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:0.6902047137956362, roc_auc:0.7119764661012618\n"
     ]
    }
   ],
   "source": [
    "#model.load(\"model_save_FFM_emb_seed_1.pt\")\n",
    "model.load(\"model_save_FM_emb_seed_1.pt\")\n",
    "total_loss, roc_auc = validation(model, test_iter, criterion)\n",
    "print(f\"loss:{total_loss}, roc_auc:{roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FM_emb and FFM_emb result(use epoch 50)\n",
    "# ffm: 0.74097810204624\n",
    "# fm: 0.7313277392961333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_all_data(data_iter):\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    for nbatch, batch in enumerate(data_iter):\n",
    "        \"\"\"\n",
    "        feature shape: (B, Field_num)\n",
    "        \"\"\"\n",
    "        features, labels = convert_feature(batch, use_one_hot=False)\n",
    "        data_list.append(features.data.numpy())\n",
    "        label_list.extend(labels.numpy())\n",
    "    return np.concatenate(data_list, axis=0), label_list\n",
    "\n",
    "train_data, train_label = integrate_all_data(train_iter)\n",
    "val_data, val_label = integrate_all_data(val_iter)\n",
    "test_data, test_label = integrate_all_data(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "model = CatBoostClassifier(iterations=2,\n",
    "                           depth=1,\n",
    "                           learning_rate=0.1,\n",
    "                           loss_function='Logloss',\n",
    "                           early_stopping_rounds=30,\n",
    "                           verbose=False,\n",
    "                           task_type='CPU',\n",
    "                           devices='0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fe0d30b9710>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = [0, 1]\n",
    "model.fit(train_data, train_label, cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_for_catboost(model, data, data_label):\n",
    "    preds_proba = model.predict(data, prediction_type='Probability')\n",
    "    probs = []\n",
    "    for l, row in zip(data_label, preds_proba):\n",
    "        probs.append(row[int(l)])\n",
    "    results = roc_auc_score(data_label, probs)\n",
    "    return results, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, probs = validation_for_catboost(model, val_data, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7141420457106172"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
