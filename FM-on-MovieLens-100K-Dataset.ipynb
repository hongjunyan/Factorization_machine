{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tutorial website: https://medium.com/@julsimon/building-a-movie-recommender-with-factorization-machines-on-amazon-sagemaker-cedbfc8c93d8\n",
    "#### dataset: https://grouplens.org/datasets/movielens/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "#### Before you read this code, Please study Tutorial website above.\n",
    "#### Given user_id and Movie_id, the model can determine whether this user_id likes this movie_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import for Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# for time\n",
    "from time import time\n",
    "\n",
    "# for dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# load parameters\n",
    "from bunch import Bunch\n",
    "args = Bunch({\n",
    "    'epochs':20,\n",
    "    'lr':1e-3,\n",
    "    'batch_size':128,\n",
    "    'eval_step':500,\n",
    "    'load_dir':'',\n",
    "    'save_dir':'./model_save',\n",
    "    'seed':1,\n",
    "    'device': 0\n",
    "})\n",
    "\n",
    "###############\n",
    "\"\"\"device\"\"\"\n",
    "use_gpu = args.device is not None\n",
    "if torch.cuda.is_available() and not use_gpu:\n",
    "    print(\"WARNING: You have a CUDA device, should run with -device 0\")\n",
    "# set cuda device and seed\n",
    "if use_gpu:\n",
    "    torch.cuda.set_device(args.device)\n",
    "    \n",
    "\"\"\"set seed\"\"\"\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import pandas as pd\n",
    "import json\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, csv_file, header=None, delimiter='\\t'):\n",
    "        \"\"\"\n",
    "        user_id: 1~943\n",
    "        movie_id: 1~1682\n",
    "        \"\"\"\n",
    "        self.dataframe = pd.read_csv(csv_file, header=header, delimiter=delimiter)\n",
    "        self.column_num = len(self.dataframe.columns)\n",
    "        # rename column\n",
    "        self.rename_column(['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "\n",
    "        # however len(self.dataframe['movie_id'].value_counts()) == 1680\n",
    "        self.user_num = self.dataframe['user_id'].value_counts().keys().max()\n",
    "        self.movie_num = self.dataframe['movie_id'].value_counts().keys().max() # 1682\n",
    "        \n",
    "        # set labels = True if rating >3 else labels=False\n",
    "        self.dataframe['labels'] = self.dataframe['rating']>3\n",
    "    \n",
    "    def rename_column(self, name_list):\n",
    "        assert self.column_num == len(name_list)\n",
    "        self.dataframe.columns = name_list\n",
    "        \n",
    "    def show_labels_proportion(self):\n",
    "        #label_True_count/Total_num_of_dataframe\n",
    "        return self.dataframe['labels'].sum()/len(self.dataframe['labels'])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return json.loads(self.dataframe.iloc[idx].to_json(orient='columns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels proportion(True_count/Total_num) 0.5510213094843768\n",
      "Train labels proportion(True_count/Total_num) 0.5799575821845175\n"
     ]
    }
   ],
   "source": [
    "# load training dataset\n",
    "train_dataset = Dataset('./datasets/ml-100k/ua.base')\n",
    "\n",
    "# load testing dataset\n",
    "test_dataset = Dataset('./datasets/ml-100k/ua.test')\n",
    "\n",
    "print(\"Train labels proportion(True_count/Total_num)\", train_dataset.show_labels_proportion())\n",
    "print(\"Train labels proportion(True_count/Total_num)\", test_dataset.show_labels_proportion())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_num = train_dataset.user_num\n",
    "movie_num = train_dataset.movie_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size:81513, validation size:9057, test size:9430\n"
     ]
    }
   ],
   "source": [
    "# split train val dataset\n",
    "from torch.utils.data import random_split\n",
    "val_size = int(len(train_dataset)*0.1)\n",
    "train_size = len(train_dataset) - val_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "print(\"train size:{}, validation size:{}, test size:{}\".format(train_size, val_size, len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataLoader\n",
    "train_iter = DataLoader(dataset=train_dataset,\n",
    "                        batch_size=args.batch_size)\n",
    "\n",
    "val_iter = DataLoader(dataset=val_dataset,\n",
    "                        batch_size=args.batch_size)\n",
    "\n",
    "test_iter = DataLoader(dataset=test_dataset,\n",
    "                        batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baic module\n",
    "## make you convient to save and load your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "class BasicModule(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super(BasicModule,self).__init__()\n",
    "        self.args = args\n",
    "        self.model_name = str(type(self))\n",
    "    \n",
    "    def save(self):\n",
    "        checkpoint = {'model':self.state_dict(), 'args': self.args}\n",
    "        best_path = '%s_%s_seed_%d.pt' % (self.args.save_dir,self.model_name,self.args.seed)\n",
    "        torch.save(checkpoint,best_path)\n",
    "\n",
    "        return best_path\n",
    "\n",
    "    def load(self, best_path):\n",
    "        if best_path == \"\":\n",
    "            best_path = self.args.load_dir\n",
    "        if self.args.device is not None:\n",
    "            data = torch.load(best_path)['model']\n",
    "        else:\n",
    "            data = torch.load(best_path, map_location=lambda storage, loc: storage)['model']\n",
    "        self.load_state_dict(data)\n",
    "        if self.args.device is not None:\n",
    "            return self.cuda()\n",
    "        else:\n",
    "            return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf\n",
    "# https://www.kaggle.com/gennadylaptev/factorization-machine-implemented-in-pytorch/data\n",
    "class FM(BasicModule):\n",
    "    def __init__(self, args, n=None, k=None):\n",
    "        super(FM, self).__init__(args)\n",
    "        self.model_name = 'FM'\n",
    "        # Initially we fill V with random values sampled from Gaussian distribution\n",
    "        # use nn.Parameter to compute gradients\n",
    "        self.args = args\n",
    "        self.V = nn.Parameter(torch.FloatTensor(n, k).normal_(0,1))\n",
    "        self.linear = nn.Linear(n, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out_1 = torch.matmul(x, self.V).pow(2).sum(1, keepdim=True) #S_1^2\n",
    "        out_2 = torch.matmul(x.pow(2), self.V.pow(2)).sum(1, keepdim=True) # S_2\n",
    "        # out_1, out_2 shape are (B, k) \n",
    "        out_inter = 0.5*(out_1 - out_2)\n",
    "        out_lin = self.linear(x)\n",
    "        out = out_inter + out_lin\n",
    "        out = torch.sigmoid(out) # (B,1)\n",
    "        return out.squeeze() # (B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FM with embedding layer \n",
    "## The same as FM, but using nn.Embedding can be more convient to extend the first and seconder parameter, i.e., you can modify the dimension of nn.Embedding from nn.Embedding(feature_size,1) to nn.Embedding(feature_size, D_model), the value of D_model is up to you\n",
    "<img src=\"attachements/FM.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM_emb(BasicModule):\n",
    "    def __init__(self, args, feature_sizes, k=None):\n",
    "        super(FM_emb, self).__init__(args)\n",
    "        self.model_name = 'FM_emb'\n",
    "        self.feature_sizes = feature_sizes # list [field1_categories_num, field2_categories_num, ...]\n",
    "        self.args = args\n",
    "        self.embedding_size = k\n",
    "        self.first_order_embeddings = nn.ModuleList([nn.Embedding(feature_size,1) for feature_size in self.feature_sizes])\n",
    "        self.second_order_embeddings = nn.ModuleList([nn.Embedding(feature_size, self.embedding_size) for feature_size in self.feature_sizes])\n",
    "        \n",
    "        \n",
    "    def forward(self, x, values, use_sigmoid=True):\n",
    "        fields_first_order = [torch.sum(emb(x[:,i]), dim=1, keepdim=True)*values[:,i].unsqueeze(1) for i, emb in enumerate(self.first_order_embeddings)] # [(B,1), (B,1)]\n",
    "        fm_first_order = sum(fields_first_order)# (B,2) sum-> (B,1)\n",
    "        \n",
    "        # a,b are vector\n",
    "        # use 2*a.dot(b)xy = (ax+by)^2 - a^2x^2 - b^2y^2 reduce calculation\n",
    "        fm_second_order_emb_arr = [torch.sum(emb(x[:,i]), dim=1, keepdim=True)*values[:,i].unsqueeze(1) for i, emb in enumerate(self.second_order_embeddings)] # [(B,1), (B,1)]\n",
    "        fm_sum_second_order_emb = sum(fm_second_order_emb_arr)\n",
    "        fm_sum_second_order_emb_square = fm_sum_second_order_emb*fm_sum_second_order_emb # (x+y)^2\n",
    "        fm_second_order_emb_square = [item*item for item in fm_second_order_emb_arr]\n",
    "        fm_second_order_emb_square_sum = sum(fm_second_order_emb_square) #x^2+y^2\n",
    "        fm_second_order = (fm_sum_second_order_emb_square - fm_second_order_emb_square_sum) * 0.5\n",
    "        \n",
    "        out = fm_first_order + fm_second_order\n",
    "        if use_sigmoid:\n",
    "            return torch.sigmoid(out).squeeze() # (B,1) squeeze-> (B)\n",
    "        else:\n",
    "            return out.squeeze() # (B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.csie.ntu.edu.tw/~cjlin/papers/ffm.pdf\n",
    "class FFM_emb(BasicModule):\n",
    "    def __init__(self, args, feature_sizes, k=None):\n",
    "        super(FFM_emb, self).__init__(args)\n",
    "        self.model_name = 'FFM_emb'\n",
    "        self.feature_sizes = feature_sizes # list [field1_categories_num, field2_categories_num, ...]\n",
    "        self.field_sizes = len(feature_sizes)\n",
    "        self.args = args\n",
    "        self.embedding_size = k\n",
    "        self.first_order_embeddings = nn.ModuleList([nn.Embedding(feature_size,1) for feature_size in self.feature_sizes])\n",
    "        self.second_order_embeddings = nn.ModuleList([nn.ModuleList([nn.Embedding(feature_size, self.embedding_size) for _ in range(self.field_sizes)]) for feature_size in self.feature_sizes])\n",
    "    \n",
    "    def forward(self, x, values, use_sigmoid=True):\n",
    "        # first order relation\n",
    "        \"\"\"\n",
    "        x shape: (B, Field_num)\n",
    "        value shape: (B, Field_num)\n",
    "        \"\"\"\n",
    "        # or (torch.sum(emb(x[:,i]), dim=1, keepdim=True).t()*values[:,i]).t()\n",
    "        fields_first_order = [torch.sum(emb(x[:,i]), dim=1, keepdim=True)*values[:,i].unsqueeze(1) for i, emb in enumerate(self.first_order_embeddings)] # [(B,1), (B,1)]\n",
    "        fm_first_order = sum(fields_first_order)# (B,1)+(B,1)+...-> (B,1)\n",
    "        \n",
    "        # second order relation\n",
    "        \"\"\"\n",
    "        fm_second_order_emb_arr (field_sizes, field_sizes)\n",
    "        |[(B,1), (B,1), (B,1) ...]\n",
    "        |[(B,1), (B,1), (B,1) ...]\n",
    "        |[(B,1), (B,1), (B,1) ...]\n",
    "                . \n",
    "                .\n",
    "                .\n",
    "        \"\"\"\n",
    "        ffm_second_order_emb_arr = [[torch.sum(emb(x[:,i]), dim=1, keepdim=True)*values[:,i].unsqueeze(1) for emb in field_embs] for i, field_embs in enumerate(self.second_order_embeddings)]\n",
    "        ffm_wij_arr = []\n",
    "        for i in range(self.field_sizes):\n",
    "            for j in range(i+1, self.field_sizes):\n",
    "                ffm_wij_arr.append(ffm_second_order_emb_arr[i][j]*ffm_second_order_emb_arr[j][i])\n",
    "        ffm_second_order = sum(ffm_wij_arr)\n",
    "        out = fm_first_order + ffm_second_order\n",
    "        if use_sigmoid:\n",
    "            return torch.sigmoid(out).squeeze() # (B,1) squeeze-> (B)\n",
    "        else:\n",
    "            return out.squeeze() # (B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build FM model\n",
    "criterion = nn.BCELoss()\n",
    "#model = FFM_emb(args, [user_num, movie_num], k=8)\n",
    "model = FM_emb(args, [user_num, movie_num], k=64)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "if use_gpu:\n",
    "    model.cuda()\n",
    "    criterion.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess in batch(convert id to one hot encoding)\n",
    "def one_hot_encoding(idx_tensor, dim=None):\n",
    "    # only FM need this, FM_emb, FFM_emb doesn't\n",
    "    if dim==None:\n",
    "        print('Please assign a dimension num, e.g. one_hot_encoding(...,dim=10)')\n",
    "        return\n",
    "    one_hot = torch.zeros(idx_tensor.size(0), dim)\n",
    "    one_hot[torch.arange(idx_tensor.size(0)), idx_tensor] = 1\n",
    "    return one_hot\n",
    "\n",
    "def convert_feature(batch, use_one_hot=True):\n",
    "    \"\"\"\n",
    "    'user_id': [user_id, ...]\n",
    "    'movie_id': [movie_id, ...]\n",
    "    'labels': [label, ...]\n",
    "    \"\"\"\n",
    "    # convert one hot encoding\n",
    "    # the index should be minus 1, due to the id is start from 1\n",
    "    if use_one_hot:\n",
    "        users_vec = one_hot_encoding(batch['user_id']-1, dim=user_num) # B x user_num\n",
    "        movies_vec = one_hot_encoding(batch['movie_id']-1, dim=movie_num) # B x movie_num\n",
    "    else:\n",
    "        users_vec = (batch['user_id']-1).unsqueeze(1).type(torch.LongTensor)\n",
    "        movies_vec = (batch['movie_id']-1).unsqueeze(1).type(torch.LongTensor)\n",
    "    labels = batch['labels'].float()\n",
    "    \n",
    "    # concat fields vector\n",
    "    features = torch.cat((users_vec, movies_vec), dim=-1) # B x (user_num+movie_num)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def validation(model, val_iter, criterion):\n",
    "    model.eval().cpu()\n",
    "    y_pred = []\n",
    "    y = []\n",
    "    total_loss = 0.0\n",
    "    for nbatch, batch in enumerate(val_iter):\n",
    "        features, labels = convert_feature(batch, use_one_hot=False)\n",
    "        values = torch.ones(features.shape)\n",
    "        probs = model(features, values)\n",
    "        loss = criterion(probs, labels)\n",
    "        total_loss += loss.item()\n",
    "        y.extend(labels.data.numpy())\n",
    "        y_pred.extend(probs.data.numpy())\n",
    "    total_loss = total_loss/(nbatch+1)\n",
    "    results = roc_auc_score(y, y_pred)\n",
    "    model.train().cuda()\n",
    "    return total_loss, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0] save model\n",
      "[1, 0], cur_loss 11.345163056548213, metric:0.5114522058932062, batch_loss 10.903483390808105\n",
      "[1, 500] save model\n",
      "[1, 500], cur_loss 3.3731721068771794, metric:0.5141296567560935, batch_loss 3.029346466064453\n",
      "Epoch 1, train loss:2.503824505177173, metric:0.5307566150393592\n",
      "[2, 0] save model\n",
      "[2, 0], cur_loss 2.523466021242276, metric:0.5217248288228289, batch_loss 2.1613423824310303\n",
      "[2, 500] save model\n",
      "[2, 500], cur_loss 1.2096992647144156, metric:0.5351490335139425, batch_loss 0.8595420718193054\n",
      "Epoch 2, train loss:1.0324255901752872, metric:0.5630459441042184\n",
      "[3, 0] save model\n",
      "[3, 0], cur_loss 1.0336723671832555, metric:0.5462986005696755, batch_loss 1.345477819442749\n",
      "[3, 500] save model\n",
      "[3, 500], cur_loss 0.8693185054080587, metric:0.5626877408785707, batch_loss 0.8493897318840027\n",
      "Epoch 3, train loss:0.800430603360456, metric:0.5937492082859284\n",
      "[4, 0] save model\n",
      "[4, 0], cur_loss 0.8407664911847719, metric:0.5715974312058772, batch_loss 1.2367960214614868\n",
      "[4, 500] save model\n",
      "[4, 500], cur_loss 0.777434658836311, metric:0.602058687038477, batch_loss 0.7605971097946167\n",
      "Epoch 4, train loss:0.7150463749138489, metric:0.6423598024553412\n",
      "[5, 0] save model\n",
      "[5, 0], cur_loss 0.7611624724428419, metric:0.6151656154259901, batch_loss 0.8821971416473389\n",
      "[5, 500] save model\n",
      "[5, 500], cur_loss 0.7131993837759528, metric:0.665396183808394, batch_loss 0.6770739555358887\n",
      "Epoch 5, train loss:0.6447494455278387, metric:0.7093732529925263\n",
      "[6, 0] save model\n",
      "[6, 0], cur_loss 0.7025230820749847, metric:0.6734329153365024, batch_loss 0.702041745185852\n",
      "[6, 500] save model\n",
      "[6, 500], cur_loss 0.6779541348067808, metric:0.6956807322137812, batch_loss 0.6455932855606079\n",
      "Epoch 6, train loss:0.6137656772529686, metric:0.7339278020045976\n",
      "[7, 0] save model\n",
      "[7, 0], cur_loss 0.6709705893422516, metric:0.6974163420839304, batch_loss 0.6425389647483826\n",
      "[7, 500] save model\n",
      "[7, 500], cur_loss 0.660561310153612, metric:0.7094099128167917, batch_loss 0.625849187374115\n",
      "Epoch 7, train loss:0.5999017780766569, metric:0.7447053001330661\n",
      "[8, 0], cur_loss 0.6570077563675356, metric:0.7088868755607749, batch_loss 0.6137434244155884\n",
      "[8, 500] save model\n",
      "[8, 500], cur_loss 0.65109675954765, metric:0.7174911471620832, batch_loss 0.6216819286346436\n",
      "Epoch 8, train loss:0.5911696232282199, metric:0.7513139601456484\n",
      "[9, 0], cur_loss 0.6497863757778222, metric:0.7155980184757788, batch_loss 0.5940260887145996\n",
      "[9, 500] save model\n",
      "[9, 500], cur_loss 0.6447908836351314, metric:0.7234388539656168, batch_loss 0.6179169416427612\n",
      "Epoch 9, train loss:0.5848210875523895, metric:0.7564858634449865\n",
      "[10, 0], cur_loss 0.6455883039555079, metric:0.7204458242531842, batch_loss 0.5808356404304504\n",
      "[10, 500] save model\n",
      "[10, 500], cur_loss 0.6409450106217828, metric:0.728460119866825, batch_loss 0.6161017417907715\n",
      "Epoch 10, train loss:0.5794824169513008, metric:0.7609632646191892\n",
      "[11, 0], cur_loss 0.6424574826804685, metric:0.7242989711558766, batch_loss 0.5771195292472839\n",
      "[11, 500] save model\n",
      "[11, 500], cur_loss 0.6387549974548985, metric:0.732403404039921, batch_loss 0.6123237609863281\n",
      "Epoch 11, train loss:0.5752150722818808, metric:0.7646301294697981\n",
      "[12, 0], cur_loss 0.6411843845542048, metric:0.7271571147728885, batch_loss 0.5669655799865723\n",
      "[12, 500] save model\n",
      "[12, 500], cur_loss 0.6368838892856115, metric:0.7359012910294326, batch_loss 0.6098311543464661\n",
      "Epoch 12, train loss:0.5715258354481947, metric:0.7678915274980448\n",
      "[13, 0], cur_loss 0.6401076216093251, metric:0.7300113222645553, batch_loss 0.5633627772331238\n",
      "[13, 500] save model\n",
      "[13, 500], cur_loss 0.6294633141705688, metric:0.7388538524531607, batch_loss 0.6058910489082336\n",
      "Epoch 13, train loss:0.5685506941197993, metric:0.7705702543923074\n",
      "[14, 0], cur_loss 0.6325478679697278, metric:0.7325038244377886, batch_loss 0.5577333569526672\n",
      "[14, 500] save model\n",
      "[14, 500], cur_loss 0.6354708696754885, metric:0.7409938500009545, batch_loss 0.6030799746513367\n",
      "Epoch 14, train loss:0.5659063150126669, metric:0.772991507762806\n",
      "[15, 0], cur_loss 0.6323813502217682, metric:0.7343215517229503, batch_loss 0.5547624230384827\n",
      "[15, 500] save model\n",
      "[15, 500], cur_loss 0.6277677437789003, metric:0.7430929856475094, batch_loss 0.6000978946685791\n",
      "Epoch 15, train loss:0.5636946196833061, metric:0.7750808686924548\n",
      "[16, 0], cur_loss 0.6322931445820231, metric:0.7363826299575744, batch_loss 0.5497063994407654\n",
      "[16, 500] save model\n",
      "[16, 500], cur_loss 0.6274925902695723, metric:0.7446909541344963, batch_loss 0.5988590121269226\n",
      "Epoch 16, train loss:0.561515092054379, metric:0.7770962010289157\n",
      "[17, 0], cur_loss 0.6326944122851734, metric:0.7380172536118377, batch_loss 0.5511457920074463\n",
      "[17, 500] save model\n",
      "[17, 500], cur_loss 0.6274562633373368, metric:0.7465180543181362, batch_loss 0.5958199501037598\n",
      "Epoch 17, train loss:0.559560915551717, metric:0.7790296392740924\n",
      "[18, 0], cur_loss 0.6324919231340919, metric:0.7398089040665882, batch_loss 0.5450205206871033\n",
      "[18, 500] save model\n",
      "[18, 500], cur_loss 0.6356416932294067, metric:0.7473028439096037, batch_loss 0.5941802263259888\n",
      "Epoch 18, train loss:0.5580327950616834, metric:0.7805796346391862\n",
      "[19, 0], cur_loss 0.6337574250261548, metric:0.7406393527120594, batch_loss 0.5396459698677063\n",
      "[19, 500] save model\n",
      "[19, 500], cur_loss 0.6306813224940233, metric:0.7485078148816634, batch_loss 0.5926461219787598\n",
      "Epoch 19, train loss:0.5564579405065982, metric:0.782172080390173\n",
      "[20, 0], cur_loss 0.6336339145479067, metric:0.7418047656244002, batch_loss 0.5385918021202087\n",
      "[20, 500] save model\n",
      "[20, 500], cur_loss 0.6398524646188172, metric:0.7489310713601811, batch_loss 0.5917056798934937\n",
      "Epoch 20, train loss:0.5547213668070933, metric:0.7836627039309267\n"
     ]
    }
   ],
   "source": [
    "stime = time()\n",
    "model.train()\n",
    "total_loss = []\n",
    "best_roc = -float('inf')\n",
    "for epoch in range(1,args.epochs+1):\n",
    "    etime = time()\n",
    "    for nbatch, batch in enumerate(train_iter):\n",
    "        \"\"\"\n",
    "        feature shape: (B, Field_num)\n",
    "        values shape: (B, Field_num)\n",
    "        \"\"\"\n",
    "        # only FM need ont_hot_encoding, FM_emb, FFM_emb doesn't\n",
    "        # so use_one_hot=True for FM, else use_one_hot=False\n",
    "        features, labels = convert_feature(batch, use_one_hot=False)\n",
    "        \n",
    "        # value in original category. However, in this datase all of values are 1\n",
    "        values = torch.ones(features.shape)\n",
    "        if use_gpu:\n",
    "            features, labels, values = features.cuda(), labels.cuda(), values.cuda()\n",
    "        probs = model(features, values)\n",
    "        loss = criterion(probs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if nbatch % args.eval_step==0:\n",
    "            cur_loss, results = validation(model, val_iter, criterion)\n",
    "            if best_roc < results:\n",
    "                best_roc = results\n",
    "                best_path = model.save()\n",
    "                print(\"[{}, {}] save model\".format(epoch, nbatch))\n",
    "            print(\"[{}, {}], cur_loss {}, metric:{}, batch_loss {}\".format(epoch, nbatch, cur_loss, results, loss.item()))\n",
    "    epoch_loss, results = validation(model, train_iter, criterion)\n",
    "    total_loss.append(epoch_loss)\n",
    "    print(\"Epoch {}, train loss:{}, metric:{}\".format(epoch, epoch_loss, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6902028644407118 0.7119771123731571\n"
     ]
    }
   ],
   "source": [
    "#model.load(\"model_save_FFM_emb_seed_1.pt\")\n",
    "model.load(\"model_save_FM_emb_seed_1.pt\")\n",
    "total_loss, roc_auc = validation(model, test_iter, criterion)\n",
    "print(total_loss, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FM and FFM result(use epoch 50)\n",
    "ffm: 0.74097810204624\n",
    "fm: 0.7313277392961333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_all_data(data_iter):\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    for nbatch, batch in enumerate(data_iter):\n",
    "        \"\"\"\n",
    "        feature shape: (B, Field_num)\n",
    "        \"\"\"\n",
    "        features, labels = convert_feature(batch, use_one_hot=False)\n",
    "        data_list.append(features.data.numpy())\n",
    "        label_list.extend(labels.numpy())\n",
    "    return np.concatenate(data_list, axis=0), label_list\n",
    "\n",
    "train_data, train_label = integrate_all_data(train_iter)\n",
    "val_data, val_label = integrate_all_data(val_iter)\n",
    "test_data, test_label = integrate_all_data(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "model = CatBoostClassifier(iterations=2,\n",
    "                           depth=1,\n",
    "                           learning_rate=0.1,\n",
    "                           loss_function='Logloss',\n",
    "                           early_stopping_rounds=30,\n",
    "                           verbose=False,\n",
    "                           task_type='GPU',\n",
    "                           devices='0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f6409c0fcf8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = [0, 1]\n",
    "model.fit(train_data, train_label, cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_for_catboost(model, data, data_label):\n",
    "    preds_proba = model.predict(data, prediction_type='Probability')\n",
    "    probs = []\n",
    "    for l, row in zip(data_label, preds_proba):\n",
    "        probs.append(row[int(l)])\n",
    "    results = roc_auc_score(data_label, probs)\n",
    "    return results, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, probs = validation_for_catboost(model, train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8296218254277431"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
